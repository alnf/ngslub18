{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #1\n",
    "#### What are best options for remote synchronization using *rsync*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts:\n",
    "- what about subfolders?\n",
    "- what about links in folders?\n",
    "- what about unchanged access permitions on each file (owner is owner)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* -a, --archive               archive mode; equals -rlptgoD (no -H,-A,-X)<br>\n",
    "* -r, --recursive             recurse into directories<br>\n",
    "* -l, --links                 copy symlinks as symlinks<br>\n",
    "* -p, --perms                 preserve permissions<br>\n",
    "* -t, --times                 preserve modification times<br>\n",
    "* -g, --group                 preserve group<br>\n",
    "     --devices               preserve device files (super-user only)<br>\n",
    "     --specials              preserve special files<br>\n",
    "* -D                          same as --devices --specials<br>\n",
    "* -o, --owner                 preserve owner (super-user only)<br>\n",
    "\n",
    "\n",
    "* -z, --compress              compress file data during the transfer\n",
    "     --compress-level=NUM    explicitly set compression level   ex. 9\n",
    "* --partial-dir=DIR       put a partially transferred file into DIR\n",
    "* --partial               keep partially transferred files\n",
    "* -h, --human-readable        output numbers in a human-readable format\n",
    "* --no-o \n",
    "* --groupmap=*:GROUPONREMOTE \n",
    "* --chmod=Dg+s,ug+r,go-w,o-rwx to change permision\n",
    "\n",
    "Incremental recursion can be disabled using the --no-inc-recursive\n",
    "    option or its shorter --no-i-r alias. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsync -a --compress --compress-level=9 --info=progress2 --no-i-r --human-readable --partial-dir=.rsync-partial --partial --perms --no-o --groupmap=*:group_name --chmod=Dg+s,ug+r,go-w,o-rwx -e ssh /from/where/copy/files/ --rsync-path=mkdir -p \"\" && rsync /\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo rsync -a --compress --compress-level=9 \\\n",
    "--info=progress2 --no-i-r --human-readable \\\n",
    "--partial-dir=.rsync-partial --partial \\\n",
    "--perms --no-o --groupmap=*:group_name --chmod=Dg+s,ug+r,go-w,o-rwx \\\n",
    "    -e ssh /from/where/copy/files/ --rsync-path=\"mkdir -p \\\"${REMOTE_DIR}${OUTDIR}\\\" && rsync\" \"${REMOTE}${OUTDIR}/\"\n",
    "\n",
    "#for i in $(seq 10); do sleep 1; echo $i; done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practise #2\n",
    "#### What options need to be added to run rsync live... safely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts:\n",
    "- what about half-created files?\n",
    "- when to finish coping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- -partial-dir=DIR       put a partially transferred file into DIR\n",
    "- -partial               keep partially transferred files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo TODATE=\"$(date --date '+48 hours 20 minutes' +%s)\" \\\n",
    "&& while [ $TODATE -ge \"$(date +%s)\" ]; do rsync_scipt.sh sample_name_dir; sleep 1200; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *How to rsync only files in fastq format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #1\n",
    "Divide file into 3 equal files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/21034373/how-to-load-edit-run-save-text-files-py-into-an-ipython-notebook-cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example.fasta\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.fasta\n",
    ">1\n",
    "ACGT\n",
    ">2\n",
    "GCTA\n",
    ">3\n",
    "TTTT\n",
    ">4\n",
    "ACCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Snakefile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Snakefile\n",
    "\n",
    "rule divide_into_3:\n",
    "    input: seq=\"{name}.fasta\",\n",
    "    output: seq1=\"{name}1.fasta\",\n",
    "            seq2=\"{name}2.fasta\",\n",
    "            seq3=\"{name}3.fasta\",            \n",
    "    shell: \"\"\"\n",
    "        awk '{{nr=int((NR-1)/2)%3+1; x=\"{wildcards.name}\"nr\".fasta\";}}{{print > x}}' \"{input.seq}\"\n",
    "    \"\"\" # (this string goes through .format(snake_variables_dictionary))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> example1.fasta <==\n",
      ">1\n",
      "ACGT\n",
      ">4\n",
      "ACCC\n",
      "\n",
      "==> example2.fasta <==\n",
      ">2\n",
      "GCTA\n",
      "\n",
      "==> example3.fasta <==\n",
      ">3\n",
      "TTTT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /bin/bash\n",
      "Provided cores: 1\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tdivide_into_3\n",
      "\t1\n",
      "\n",
      "[Tue Sep 18 12:25:32 2018]\n",
      "rule divide_into_3:\n",
      "    input: example.fasta\n",
      "    output: example3.fasta, example2.fasta, example1.fasta\n",
      "    jobid: 0\n",
      "    wildcards: name=example\n",
      "\n",
      "[Tue Sep 18 12:25:32 2018]\n",
      "Finished job 0.\n",
      "1 of 1 steps (100%) done\n",
      "Complete log: /mnt/zgmvol/_forge/wkolczynska/workspace/genXone/brca/report/src/.snakemake/log/2018-09-18T122532.051400.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snakemake example3.fasta -f && tail -n +1 example{1,2,3}.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practise #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Snakefile\n",
    "# TASK write \n",
    "# Warning, please generate strings (output list, shell) using + operator on strings, not .format function (ask for explanation why :)\n",
    "n=5\n",
    "rule divide_into_n:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Snakefile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Snakefile\n",
    "# TASK write \n",
    "# Warning, please generate strings (output list, shell) using + operator on strings, not .format function (ask for explanation why :)\n",
    "n=4\n",
    "rule divide_into_n:\n",
    "    input: seq=\"{name}.fasta\",\n",
    "    output: [\"{name}\"+str(i)+\".fasta\" for i in range(1,n+1)],            \n",
    "    shell: \"\"\"\n",
    "        awk '{{nr=int((NR-1)/2)%\"\"\"+str(n)+\"\"\"+1; x=\"{wildcards.name}\"nr\".fasta\";}}{{print > x}}' \"{input.seq}\"\n",
    "    \"\"\" # (this string goes through .format(snake_variables_dictionary))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> example1.fasta <==\n",
      ">1\n",
      "ACGT\n",
      "\n",
      "==> example2.fasta <==\n",
      ">2\n",
      "GCTA\n",
      "\n",
      "==> example3.fasta <==\n",
      ">3\n",
      "TTTT\n",
      "\n",
      "==> example4.fasta <==\n",
      ">4\n",
      "ACCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /bin/bash\n",
      "Provided cores: 1\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tdivide_into_n\n",
      "\t1\n",
      "\n",
      "[Tue Sep 18 12:28:09 2018]\n",
      "rule divide_into_n:\n",
      "    input: example.fasta\n",
      "    output: example1.fasta, example2.fasta, example3.fasta, example4.fasta\n",
      "    jobid: 0\n",
      "    wildcards: name=example\n",
      "\n",
      "[Tue Sep 18 12:28:09 2018]\n",
      "Finished job 0.\n",
      "1 of 1 steps (100%) done\n",
      "Complete log: /mnt/zgmvol/_forge/wkolczynska/workspace/genXone/brca/report/src/.snakemake/log/2018-09-18T122809.736711.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snakemake example3.fasta -f && tail -n +1 example{1,2,3,4}.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "Case when the number of outputs is unknown or large. If all downstream rules rely on the whole sets of outputs, rather than on the individual files, and when we want to create output for for example every sample we have, 'dynamic' keyword.\n",
    "This rule will launch other rules which are necessary to create files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule all_centrifuge_aggregated:\n",
    "    input:[dynamic(\"{{numer}}/{{number}}.from_centrifuge\".format(suffix)) for suffix in [\"noEuca__krona.html\", \"classification_krona.html\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 3\n",
    "### Snakemake\n",
    "\n",
    "Using snakemake create 3 rules that enable creation of:\n",
    "1. ...150 random sequences in FASTA format (each from 50 to 100bp). Put them randomly in 3 files, so that each file contains 100 sequences (sequences can be repeated in files or even in one file). PYTHON lub bas (shuff)\n",
    "2. ... another file (tab separated) containing any sequence that occurred in the files and at least: the number of different files in which it was placed, and the number of all counts. SHELL\n",
    "3. ... interesting histograms based on 4th file (each sequence in the number of files). R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practise #4\n",
    "Convert fastq file into fasta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat example.fastq | awk 'NR%4 == 1 {print \">\" substr($0, 2)} NR%4 == 2 {print}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What about multilines fastq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #5\n",
    "\n",
    "Get randomly 10% of data from fasta file (2 lines == one record, don’t split it!). \n",
    "\n",
    "Pseudorandom != random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #7\n",
    "What options of BLAST could help improved outputs for nanopore data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paramset:\n",
    "- -task blastn/blastp/tblastn/blastx\n",
    "- -num_threads \n",
    "- -db\n",
    "- -max_target_seqs  \n",
    "- -evalue\n",
    "- -word_size \n",
    "- -max_hsps  \n",
    "- -outfmt\n",
    "    - %f means sequence in FASTA format\n",
    "    - %s means sequence data (without defline)\n",
    "    - %l means sequence length\n",
    "    - %T means taxid\n",
    "    - %L means common taxonomic name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #8\n",
    "#### RUN BLAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "0. Download database from:\n",
    "ftp://ftp.ncbi.nlm.nih.gov/blast/db/16SMicrobial.tar.gz\n",
    "\n",
    "1. Prepare sample:\n",
    "fastq into fasta\n",
    "\n",
    "2. Run Blast:\n",
    "/mnt/zgmvol/environment/software/sources/genXone/ncbi-blast-2.7.1+-src/c++/ReleaseMT/bin/blastn   -num_threads 32    -evalue  1e3      -word_size 15    -max_hsps  1     -max_target_seqs 5\n",
    "-db path_to_baza    -query input.fasta \n",
    "-outfmt \"{params.outfmt}\" > output.tsv\n",
    "\n",
    "3. Filtr:\n",
    " \"{params.script}\" blastFilter \"{input.datain}\" \"{params.dmp}\" \"{output.dataout}\" {params.all_flag} -l \"{output.datalog}\"\n",
    "\n",
    "4. Count \n",
    "datamash --sort -g 3 count 3 mean 4 median 4 mean 5 median 5 < \"{input.datain}\" | sort -k 2rn,2 -k 1 > \"{output.dataout}\"  #BLAST_OUTPUT='6 qseqid sseqid staxids bitscore length qlen mismatch score evalue'\n",
    "\n",
    "5. from blast to krakn\n",
    " awk 'BEGIN{{ print \"readID\\tseqID\\ttaxID\\tscore\\t2ndBestScore\\thitLength\\tqueryLength\\tnumMatches\"; FS=\"\\t\"; OFS=\"\\t\";}}{{print   $1, $2,$3, $8, 0, $5, $6, 1 }} ' \"{input.datain}\" > \"{output.dataout}\" && centrifuge-kreport -x \"{params.db}\" \"{output.dataout}\" > \"{output.krakn}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice #9\n",
    "1. Pavian\n",
    "\n",
    "- Check how many Bacterial and Viral reads are in sample. \n",
    "- Create visualization in the form of a text and graphical tree. \n",
    "- Compare 2 samples in PAVIAN. Create CSV and TSV file with this comparison. \n",
    "\n",
    "2. Krona\n",
    "- Compare results from KRONA and Pavian. Where are the defferences?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
